# 运维监控讲义

## 一、运维监控

### 1. 概述

俗话说：无监控、不运维，运维监控的地位不言而喻，尤其是在当前这个运维自动化时代，无论是传统运维、DevOps，亦或是 SRE，监控都是一项必备的技能。

通过建立完善的运维监控体系，我们可以实现以下目标：

- **长期趋势分析**：通过对监控样本数据的持续收集和统计，对监控指标进行长期趋势分析。例如，通过对磁盘空间增长率的判断，我们可以提前预测在未来什么时间节点上需要对资源进行扩容。
- **对照分析**：两个版本的系统运行资源使用情况的差异如何？在不同容量情况下系统的并发和负载变化如何？通过监控能够方便的对系统性能进行跟踪和比较。
- **告警**：当系统出现或者即将出现故障时，监控系统需要迅速反应并通知管理员，从而能够对问题进行快速的处理或者提前预防问题的发生，避免对业务造成影响。
- **故障分析与定位**：当问题发生后，需要对问题进行调查和处理。通过对不同监控监控以及历史数据的分析，能够找到并解决根源问题。
- **数据可视化**：通过可视化仪表盘能够直接获取系统的运行状态、资源使用情况、以及服务运行状态等直观的信息。

### 2. 黑/白盒监控

《SRE：Google 运维解密》一书指出，监控系统需要能够有效的支持 **白盒监控** 和 **黑盒监控**。黑盒监控指的是监控外部用户可见的系统行为，白盒监控指的是监控内部暴露出来的指标信息。它们一个对外，一个对内。

通过白盒监控，我们能够了解其系统内部的实际运行状态，通过对监控指标的观察能够预判可能出现的问题，从而对潜在的不确定因素进行优化。

而黑盒监控，常见的如 HTTP 探针，TCP 探针等，可以在系统或者服务在发生故障时能够快速通知相关的人员进行处理。

具体而言，黑盒监控与白盒监控主要有两个区别：

- **监控角度不同**：黑盒更偏向于外侧，可以理解为是通过某个功能或者具体的某个接口来观察，它并不清楚内部是如何实现的；而白盒则更倾向于从内侧监控，它是代码层面的，从内部的视角来解读整个系统。

- **面向对象不同**：黑盒更倾向于看到这个问题的现象，比如某个端口挂掉了无法再提供服务，它面向的是当下所发生的故障；白盒则更加倾向于面向产生问题的原因，比如我们在日志中可以通过堆栈信息分析出故障的根源。

在实践中，我们通常会大量运用白盒监控来查看问题或是分析问题产生的原因。但这样一来，是不是说黑盒就没什么用了呢？其实不然。

我们刚刚说过，黑盒所监控的内容更偏向用户。也就是说，当系统出现问题时，我们当然可以通过白盒监控来排查问题的原因，但是如果没有黑盒监控，我们就不一定能够知道这个问题在用户那里是怎么表现的。这个时候，黑盒监控就能够弥补白盒监控的不足，展现故障在用户端的真实表现形式。

所以，黑盒监控与白盒监控之间并没有优劣的对比，它们各自有偏向的重点，只有将两者结合起来使用，才能实现最有效的运维监控。

### 3. 监控维度

#### 3.1 黑盒监控

黑盒监控一般可以细分为如下四个维度：

- **端口状态**：通过 Ping、TCPPing 等方式检测具体业务的端口是否存活。这种方式可以简单确定程序是否有在提供服务，如果连端口都无法连接，那么系统肯定出现了问题。通常情况下，我们会将端口检测和进程检测结合起来使用，如果进程存活，但是端口不存在，则说明可能程序存在某些问题，没有将服务暴露出来。

- **证书检测**：通过检测 SSL 证书是否有效，确认用户是否可以正常访问。目前，几乎所有正式的业务网站和服务接口都使用了 HTTPS，一旦证书出现了问题（例如过期或被 CA 吊销等），即使服务本身是健康的，用户也无法正常访问。

- **探活**：通过心跳检测来判定服务是否存活，比如定期通过具体的某个接口检测我们的服务是否运行正常。如果在这里出现异常，则说明我们的系统存在问题。

- **端到端功能检测**：是通过定期进行端到端的测试，结合业务流程感知业务是否在执行正常。例如使用接口自动化测试工具，来确认页面中返回的数据是否是正确的。

#### 3.2 白盒监控

白盒监控主要有下面几种监控维度：

**日志**：通过日志记录了解程序的运行状态，以及程序中是否存在异常。

**指标**：数值形式的指标可以帮助我们了解到系统中的数据走向、流量情况等。

**链路**：结合日志，通过分析 Stack Trace 等方式细粒度到代码行级别进行链路可视化，可以帮助我们了解程序的执行流程。

### 4. 黄金指标

**黄金指标** 这个概念最早由 Google SRE 团队提出，是 Google 针对大量分布式监控的经验总结，它可以在服务级别帮助衡量终端用户体验以及服务中断对业务造成的影响等问题。

黄金指标包含 **错误**、**延迟**、**流量 **和 **饱和度** 四类指标。无论要监控的数据有多么复杂、多么令人眼花缭乱，都可以归纳在这四类之中。

下面，我们依次对这四类指标进行详细说明。

#### 4.1 错误

**错误 **指的是当前系统所有发生过的错误请求，我们可以通过错误请求个数计算出相应的错误率。这个应该很容易理解，程序在运行过程中因为某些原因而导致错误的现象很常见，这些原因既可能和其他系统组件相关，也有可能是当前程序代码中的自身问题。

我们这里以 HTTP 的接口为例，有三种比较常见的错误类型：

- **显式错误**：指可以立即看出来的错误。比如在 HTTP 请求中，响应状态码出现 500，表示服务器内部产生错误。

- **隐式错误**：指表面上正常，但在数据或数据结构中出现异常的错误。例如，一个 HTTP 请求的响应状态码为 200，通常认为这个请求是成功的，但如果它所返回的业务数据无效（例如空值或者 null ），那么这个错误就是隐式的。

- **策略导致错误**：与隐式错误类似，在表面上正常，但因为违反了某些策略约束被认定为错误。例如，某个业务接口请求成功，耗时 1s，并且返回了有效的业务数据，在没有其他策略约束的情况下可以认为是正常请求。但是，如果因为各种原因，这个接口必须在 500ms 之内返回数据，也就是策略约束响应时间不得超过 500ms，那么这个数据就会因为违反策略被记录为错误。这种情况在 RPC 的提供者消费者模式中比较常见。

#### 4.2 延迟

**延迟** 指的是服务在处理请求时花费的时间。我们经常说的接口耗时或响应时长指的就是延迟。

通常情况下，我们在统计延迟时，需要分别统计成功和错误的延迟信息。以一个 HTTP 接口为例，正确的（响应状态码 200）和错误的（响应状态码 500）请求，它们的耗时一定会有差别，因为正确的请求走完了全流程，而错误的可能只进行了某一部分流程，因此这两个请求的耗时在统计时就需要分别记录。

延迟在系统中是一个十分关键的指标。很多时候，我们的服务并不会产生错误，但一定会有延迟。对于向用户暴露的服务，过高的延迟会严重影响用户体验，而在业务内部，数据库中出现的高延迟很可能会导致请求错误，这是我们需要着重关注的。

在基础层中，我们可以监控 I/O 等待、网络延迟等信息。在业务层中，则可以监控接口调用的耗时、MySQL 查询的耗时等信息。

#### 4.3 流量

**流量** 是表现系统负载情况的数据，常见的流量数值指标有 QPS（Queries Per Second，每秒请求数）和 PV（Page View，页面浏览量）等。通过这些指标，我们能够确切了解到服务当前承受了多大的压力，或者说处理请求的速度有多快。通过流量指标，我们可以得知当前系统运行的状况，以及是否到达了它的负荷上限。同时，通过持续观测流量相关的指标，例如 QPS 是否存在突增突降的情况，我们可以判断服务可用性以及服务是否遭受到了攻击等。

在基础层中，常见的监控指标有磁盘的读写速度、网络 I/O 情况等。在业务层中则有请求量、MySQL 查询次数等等。

#### 4.4 饱和度

**饱和度** 指某个资源的使用率，也就是通过这项资源的容量最大值以及现在的使用量，来判断这个资源是否“满”了。在资源饱和度过高时，某些程序或组件可能会执行缓慢，甚至无法使用。比如，当 CPU 使用率达到 100%，很多请求都会出现执行缓慢的情况。饱和度是衡量系统是否到达瓶颈的关键。如果某些饱和度指标长时间过高，我们就需要考虑扩容、减少数据量等降低饱和度的操作了。

在基础层面，需要监控的饱和度指标有 CPU 使用率、I/O 使用率、句柄使用情况等；在业务层中则需要监控线程池的线程使用数、JVM 的堆内存使用率等信息。

### 5. 可观测性

**可观测性（Observability）**这一术语源于控制论，是衡量一个系统从其外部输出的知识中推断系统内部状态的一种度量。换句话说，如果你通过观察系统的外部就能够确定它内部发生了什么，那么该系统就具有可观测性。

在 IT 运维领域，可观测性是指通过获知基础设施、编排平台和服务应用所有层面的必要信息，从而观察所有系统的各类行为是否存在异常。可观测性是通过对开发测试、IT运维、业务运营、安全合规等全业务运营流程，借助日志、指标、链路等机器数据进行关联分析，衡量、预防、发现、定位、解决业务问题，实现业务效能提升的一种能力。

「监控」是可观测性能力的一部分，任何时代都需要监控，但监控早已不再是核心需求。监控告诉我们系统哪些部分是工作的，而可观测性则告诉我们那里为什么不工作了。

传统的工具是垂直向的，在引入一个新的组件的同时也会引入一个与之对应的观测工具。尽管保证了数据的全面性，但丢失了数据的关联性和分析排查的连贯性。如果有一个统一的数据平台，把所有数据放在一个平台，似乎就能解决关联性的问题。但实际情况往往是，建立了一个观测指标、日志、链路的统一平台，数据堆在了一个地方，用的时候还是按传统的方式各看各的，关联性还得靠人的知识和经验。

因此，可观测性能力的构建，最关键的其实是**解决数据统一和关联的问题**：把之前需要人去比对、过滤的数据交给程序去处理，让人的时间更多的用在判断和决策上。

> 中国信通院《可观测性技术发展白皮书》指出，**可观测平台能力的构建，需要具备统一数据模型、统一数据处理、统一数据分析、数据编排、数据展示的能力**。

在实践中，为了解决这个问题，引入了下面即将介绍的这两个工具。

## 二、Prometheus

### 1. 介绍

[Prometheus](https://github.com/prometheus) 是一个开源的系统监控和告警工具包，能够将各项指标收集并存储为时间序列数据，即指标信息与记录时的时间戳以及称为标签的可选键值对一起存储。

Prometheus 非常适合记录任何纯数字时间序列。它既适合以机器为中心的监控，也适合高度动态的面向服务架构的监控。在微服务世界中，它对多维数据收集和查询的支持是一项特殊的优势。

![Prometheus architecture](https://prometheus.ac.cn/assets/architecture.png)

### 2. 概念

#### 2.1 Time-Series Data

 按照时间顺序记录一个系统状态变化的数据被称为 **时间序列数据（Time-Series Data）**，通常简称为 **时序数据**。

时序数据十分常见，例如：

- 某一个地区的各车辆的行驶轨迹数据以及车流量。
- 证券行业的实时交易数据。
- 系统的运行日志。

在 Prometheus 上，所有的监控样本都以时序数据的形式保存在 Prometheus 的 **TSDB（时序数据库）**中。

#### 2.2 Exporter

在 Prometheus 的架构设计中，Prometheus Server 并不直接监控特定的目标，而是专注于数据的收集，存储并且对外提供数据查询支持。因此，为了能够能够监控某些数据，Prometheus 引入了 **采集器（Exporter）** 这一概念。Exporter 运行在需要进行监控的目标上，并执行特定的监控任务。Prometheus Server 则会周期性的从 Exporter 暴露的 HTTP 服务地址拉取监控样本数据。

简单来说，Prometheus Server 使用 HTTP 协议，从安装在远程机器上的 Exporter 那里收集数据，并将这些数据存储在本地的时序数据库上。

Exporter 是一个相对开放的概念，它可以是一个独立于监控目标以外的独立运行的程序，也可以作为组件直接内置于监控目标中。只要能够通过 HTTP 协议向 Prometheus Server 提供标准格式的监控样本数据即可。

[Node Exporter](https://github.com/prometheus/node_exporter) 是一个使用 Golang 编写的、独立运行的常用 Exporter，主要通过读取 Linux 的  `/proc`  以及  `/sys`  目录下的相关文件来获取主机操作系统的诸如 CPU 使用率、内存使用率等运行状态信息。

#### 2.3 Instance & Job

在 Prometheus 中，一个暴露监控样本数据的 HTTP 服务称为一个 **实例（Instance）**。例如，在一台主机上运行的 Node Exporter 就是一个实例。

而一组用于相同采集目的的实例，或者同一个采集进程的多个副本，则通过不同的 **任务（Job）**进行管理。

#### 2.4 PromQL

**PromQL** 是 Prometheus 自定义的一套强大的数据查询语言。它使用监控指标作为查询关键字，并且内置了大量的函数，帮助用户进一步对时序数据进行诸如聚合、切片/切块、预测和连接处理等操作。

#### 2.5 Metrics

**Metrics（指标）**是监控的核心，可以简单理解为要进行监控的目标量。

Prometheus 定义了四种不同的 **指标类型（Metric Type）**：**Counter（计数器）**、**Gauge（仪表盘）**、**Histogram（直方图）**以及**Summary（摘要）**。

> Counter 类型的指标其工作方式和计数器一样，只增不减（除非系统发生重置）。例如，我们可以在应用程序中记录某些事件发生的次数，通过以时序的形式存储这些 Counter 类型的数据，我们可以轻松的了解该事件产生速率的变化。常见的监控指标，如http_requests_total（HTTP 请求总数）等都是 Counter 类型的监控指标。 
>
> 与 Counter 不同，Gauge 类型的指标侧重于反映系统的当前状态，因此这类指标的样本数据可增可减。常见指标如 node_memory_MemAvailable（可用内存大小）等都是 Gauge 类型的监控指标。通过 Gauge 指标，用户可以直接获知系统的当前状态。
>
> Histogram 和 Summary 则主要用于统计和分析样本的分布情况。
>
> 很多时候，人们都倾向于使用某些量化指标的平均值，比如 CPU 的平均使用率、页面的平均响应时间等来表示度量相关量。但这种方式的问题很明显，以 Web 程序后端 API 调用的平均响应时间为例，如果大多数 API 请求都维持在 100ms 的响应时间范围内，而个别请求的响应时间却需要 5s 甚至更长，那么就会导致页面整体的响应时间落到中位数的情况，这种现象被称为长尾问题。
>
> 解决长尾问题最简单的方式就是按照请求延迟的范围进行分组。例如，分别统计延迟在 0~10ms 之间的请求数有多少，而 10~20ms 之间的请求数又有多少。通过这种方式可以快速分析系统慢的原因。Histogram 和 Summary 类型都是为了解决这样的问题而存在的，通过 Histogram 和 Summary 类型的监控指标，我们可以快速了解样本的分布情况。

#### 2.6 Alertmanager

**Alertmanager（告警管理器）**是 Prometheus 的告警组件。Prometheus Server 根据从 Exporter 那里收集的数据，按照预先配置的**Alerting rules（告警规则）**将 **Alerts（告警信息）** 发送给 Alertmanager。Alertmanager 从 Prometheus Server 那里接受到 Alerts 后，进行去重、分组、降噪等处理，并将 Alerts 通过路由发送到正确的接收器上，例如电子邮件、Slack、WebHook 等。

### 3. 部署

Prometheus 的大部分组件都基于 Golang 编写，因此编译后的软件包无需任何第三方依赖即可运行。只需要下载对应平台的二进制包，解压并添加基本的配置后即可正常启动 Prometheus Server。

Prometheus 官方也提供了 Docker 容器镜像，便于我们快速进行部署。这里演示使用 Docker 方式部署。

#### 3.1 拉取镜像

```bash
docker pull prom/prometheus
```

#### 3.2 创建数据持久化目录

```bash
mkdir prometheus/prometheus-data
```

#### 3.3 编写基本配置文件

在当前目录下新建工作目录  `prometheus`，然后在工作目录中新建配置文件 `prometheus.yml` ：

```bash
mkdir prometheus
nano ./prometheus/prometheus.yml
```

```yaml
# default global config
global:
  scrape_interval:     15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.
  # scrape_timeout is set to the global default (10s).

# Alertmanager configuration
alerting:
  alertmanagers:
  - static_configs:
    - targets:
      # - alertmanager:9093

# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
rule_files:
  # - "first_rules.yml"
  # - "second_rules.yml"

# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
scrape_configs:
  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
  - job_name: 'prometheus'

    # metrics_path defaults to '/metrics'
    # scheme defaults to 'http'.

    static_configs:
    - targets: ['localhost:9090']
```

#### 3.4 启动 Prometheus Server 容器

```bash
docker run --name prometheus -d -p 9090:9090 -v ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml -v ./prometheus/prometheus-data:/prometheus prom/prometheus
```

在容器运行后访问 Docker 宿主机的相应端口（即`9090`），不出意外的话即可看到 Prometheus 的 WebUI：

![image-20250328174644167](https://pic1.imgdb.cn/item/67e75f260ba3d5a1d7e5d857.png)

### 4. 使用 Node Exporter 监控主机状态信息

#### 4.1 部署 Node Exporter

1. 拉取镜像

   ```bash
   docker pull prom/node-exporter
   ```

2. 启动容器

   ```bash
   docker run -d -p 9100:9100 prom/node-exporter
   ```

3. 验证 Node Exporter 是否就绪

   浏览器访问 `http://[Docker 宿主机 IP 地址]:9100/metrics`，如图所示即为就绪：
   ![image-20250328175845917](https://pic1.imgdb.cn/item/67e75f260ba3d5a1d7e5d858.png)

#### 4.2 修改 Prometheus 的配置文件

首先，停止已经运行的 Prometheus 容器：

```bash
docker stop prometheus
```

接着，编辑之前的配置文件，在  `scrape_configs` 字段下新增监控项目：

```yaml
global:
  scrape_interval:     15s
  evaluation_interval: 15s

alerting:
  alertmanagers:
  - static_configs:
    - targets:

rule_files:

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
    - targets: ['localhost:9090']
  
  # 新增用于从之前部署的 Node Exporter 那里收集监控数据的 Job：
  - job_name: 'host-status'
    static_configs:
      - targets: ['[IP]:9100']
        labels:
          instance: localhost
```

然后重新启动 Prometheus 容器：

```bash
docker start prometheus
```

最后，访问  Prometheus WebUI 的 `/targets` 路径来验证：

![image-20250328181357591](https://pic1.imgdb.cn/item/67e75f270ba3d5a1d7e5d859.png)

不过，到目前为止，我们只是将 Node Exporter 接入到了 Prometheus Server 中，还不能通过图表等方式直观地看到各项数据。为了更好地进行数据可视化，我们还需要引入 Grafana。

## 三、Grafana

### 1. 介绍

[Grafana](https://grafana.com/) 是一个开源的数据可视化和监控工具，可以连接多个数据源并实时展示数据，同时允许用户创建交互式的仪表板（Dashboard）。

Grafana 常用于以下场景：

- **系统监控**：通过与 Prometheus、InfluxDB 等数据源结合，监控服务器、容器、网络设备的运行状态。
- **业务指标监控**：结合应用程序的数据源（比如 MySQL 等数据库），监控用户增长、销售额等业务指标。
- **日志分析**：通过与 Loki、Elasticsearch 等集成，实时分析日志数据，定位问题。
- **云服务监控**：通过集成 AWS、Azure、Google Cloud 等平台的监控数据，管理和优化云资源。

### 2. 部署

#### 2.1 拉取镜像

```bash
docker pull grafana/grafana-oss
```

#### 2.2 创建数据持久化目录

```bash
mkdir grafana
```

#### 2.3 运行 Grafana 容器

```bash
docker run -d -p 5000:3000 --name=grafana -v ./grafana:/var/lib/grafana grafana/grafana-oss
```

容器启动后，即可用浏览器访问 `http://[Docker 宿主机 IP]:5000`，如果一切顺利的话将打开 Grafana 的 Web 控制台登录界面：

![image-20250329094025902](https://pic1.imgdb.cn/item/67e75f290ba3d5a1d7e5d85c.png)

使用默认的用户名 `admin` 和密码 `admin` 即可登录。

> 在首次使用默认用户名和密码登录到 Grafana Web 控制台时，Grafana 会要求修改密码。尽管这一步可以跳过，但出于安全考虑，强烈建议在此时修改密码。

![image-20250329095431265](https://pic1.imgdb.cn/item/67e75f280ba3d5a1d7e5d85b.png)

### 3. 使用 Grafana 可视化  Prometheus 监控数据

#### 3.1 配置数据源

在 `连接-数据源` 菜单中选择 `Prometheus`。

![image-20250329100250166](https://pic1.imgdb.cn/item/67e75f280ba3d5a1d7e5d85a.png)

在配置页面中填入数据源名称和连接地址，然后点击页面最下方的 `Save & Test`。

![image-20250329100531743](https://pic1.imgdb.cn/item/67e75fba0ba3d5a1d7e5d87d.png)

出现如图所示的提示即说明数据源配置成功。

![image-20250329100707810](https://pic1.imgdb.cn/item/67e75fb90ba3d5a1d7e5d87b.png)

#### 3.2 新建仪表盘

在 `仪表盘` 菜单中点击 `Create Dashboard` 按钮来创建仪表盘。

![image-20250329100945937](https://pic1.imgdb.cn/item/67e75fba0ba3d5a1d7e5d87c.png)

然后点击 `添加可视化`。

![image-20250329101032233](https://pic1.imgdb.cn/item/67e75fba0ba3d5a1d7e5d87e.png)

在数据源列表中选择我们刚刚添加的 `Prometheus` 数据源。

![image-20250329101116482](https://pic1.imgdb.cn/item/67e75fba0ba3d5a1d7e5d880.png)

选择数据源之后，就会进入仪表盘编辑界面。

![image-20250329101341370](https://pic1.imgdb.cn/item/67e7604f0ba3d5a1d7e5d8a7.png)

因为时间有限，这里不对仪表盘的具体配置方法做深入介绍。可以参考 Grafana 的 [相关文档](https://grafana.com/docs/grafana/latest/dashboards/build-dashboards/) 进行配置。

#### 3.3 导入仪表盘

在实践中，通常通过导入已经编辑好的仪表盘来快速实现特定数据的可视化。

这里，我们使用 [这个](https://grafana.com/grafana/dashboards/16098-node-exporter-dashboard-20240520-job/) 开源的 Grafana 仪表盘作为演示。

在添加仪表盘界面，选择 `导入仪表盘`。

![image-20250329103715463](https://pic1.imgdb.cn/item/67e7604f0ba3d5a1d7e5d8a6.png)

然后在图示区域输入这个仪表盘的链接地址，点击加载。

```
https://grafana.com/grafana/dashboards/16098-node-exporter-dashboard-20240520-job/
```

![image-20250329103833813](https://pic1.imgdb.cn/item/67e7604f0ba3d5a1d7e5d8a3.png)

接着，修改仪表盘名称并在下方选择数据源，最后点击 `Import` 来导入仪表盘。

![image-20250329103934661](https://pic1.imgdb.cn/item/67e7604f0ba3d5a1d7e5d8a4.png)

![image-20250329104021389](https://pic1.imgdb.cn/item/67e7604f0ba3d5a1d7e5d8a5.png)

一切顺利的话，即可看到各种数据可视化图表：

![image-20250329104210977](https://pic1.imgdb.cn/item/67e7604f0ba3d5a1d7e5d8a8.png)